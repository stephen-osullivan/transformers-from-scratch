{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Naive  Models\n",
    "\n",
    "Here we experiment with some naive models to compare the performance with transformers.\n",
    "\n",
    "We try:\n",
    "\n",
    "1) Bigram Model\n",
    "2) Average embedding over sequence length model\n",
    "3) Average embedding + final token embedding\n",
    "\n",
    "The training data is Paradise Lost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "NVIDIA GeForce RTX 3070 Laptop GPU\n",
      "tensor([[0.1560, 0.5180, 0.2055, 0.3095, 0.0988],\n",
      "        [0.6077, 0.3621, 0.9612, 0.8193, 0.2984],\n",
      "        [0.1394, 0.2113, 0.3076, 0.9631, 0.4894],\n",
      "        [0.7862, 0.2930, 0.4077, 0.2345, 0.9184],\n",
      "        [0.7753, 0.2656, 0.9476, 0.4827, 0.8621]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "#check cuda\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "X = torch.rand(5, 5).cuda()\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "\n",
    "Let's tokenize paradise lost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "456316\n"
     ]
    }
   ],
   "source": [
    "with open('paradise_lost.txt') as f:\n",
    "    text = f.read()\n",
    "print(len(text))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: paradise_lost.txt\n",
      "  input_format: \n",
      "  model_prefix: bpe_model\n",
      "  model_type: BPE\n",
      "  vocab_size: 5000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  seed_sentencepieces_file: \n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(353) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(185) LOG(INFO) Loading corpus: paradise_lost.txt\n",
      "trainer_interface.cc(409) LOG(INFO) Loaded all 10578 sentences\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(430) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(539) LOG(INFO) all chars count=455449\n",
      "trainer_interface.cc(550) LOG(INFO) Done: 99.9524% characters are covered.\n",
      "trainer_interface.cc(560) LOG(INFO) Alphabet size=59\n",
      "trainer_interface.cc(561) LOG(INFO) Final character coverage=0.999524\n",
      "trainer_interface.cc(592) LOG(INFO) Done! preprocessed 10578 sentences.\n",
      "trainer_interface.cc(598) LOG(INFO) Tokenizing input sentences with whitespace: 10578\n",
      "trainer_interface.cc(609) LOG(INFO) Done! 17279\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=10455 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2708 size=20 all=1361 active=1301 piece=es\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1649 size=40 all=2169 active=2109 piece=▁c\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1055 size=60 all=2864 active=2804 piece=▁_\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=807 size=80 all=3645 active=3585 piece=▁u\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=598 size=100 all=4166 active=4106 piece=ill\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=594 min_freq=39\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=532 size=120 all=4750 active=1544 piece=us\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=424 size=140 all=5397 active=2191 piece=ul\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=352 size=160 all=5957 active=2751 piece=ich\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=296 size=180 all=6359 active=3153 piece=ong\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=249 size=200 all=6838 active=3632 piece=▁wor\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=249 min_freq=36\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=224 size=220 all=7196 active=1351 piece=▁j\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=206 size=240 all=7698 active=1853 piece=▁fa\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=184 size=260 all=7958 active=2113 piece=▁fir\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=166 size=280 all=8393 active=2548 piece=▁im\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=154 size=300 all=8632 active=2787 piece=ree\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=153 min_freq=30\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=141 size=320 all=8929 active=1278 piece=ue\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=132 size=340 all=9167 active=1516 piece=ies\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=123 size=360 all=9412 active=1761 piece=▁day\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=115 size=380 all=9681 active=2030 piece=▁one\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=106 size=400 all=9978 active=2327 piece=▁sin\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=105 min_freq=27\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=98 size=420 all=10128 active=1138 piece=ome\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=93 size=440 all=10434 active=1444 piece=ward\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=87 size=460 all=10633 active=1643 piece=ab\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=84 size=480 all=10810 active=1820 piece=cc\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=80 size=500 all=11092 active=2102 piece=▁Con\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=80 min_freq=24\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=76 size=520 all=11265 active=1163 piece=ness\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=71 size=540 all=11521 active=1419 piece=ours\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=68 size=560 all=11761 active=1659 piece=▁hee\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=66 size=580 all=11901 active=1799 piece=▁fear\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=62 size=600 all=12069 active=1967 piece=ts\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=62 min_freq=22\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=59 size=620 all=12199 active=1115 piece=ack\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=57 size=640 all=12360 active=1276 piece=▁Nature\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=55 size=660 all=12531 active=1447 piece=▁bet\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=53 size=680 all=12649 active=1565 piece=▁power\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=51 size=700 all=12753 active=1669 piece=▁dwell\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=51 min_freq=19\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=49 size=720 all=12857 active=1102 piece=▁deep\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=47 size=740 all=13021 active=1266 piece=▁Mo\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=46 size=760 all=13142 active=1387 piece=▁disc\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=45 size=780 all=13260 active=1505 piece=itude\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=44 size=800 all=13380 active=1625 piece=▁left\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=44 min_freq=18\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=43 size=820 all=13508 active=1129 piece=▁heart\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=41 size=840 all=13660 active=1281 piece=aine\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=40 size=860 all=13729 active=1350 piece=ob\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=39 size=880 all=13863 active=1484 piece=ilde\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=38 size=900 all=13948 active=1569 piece=▁sole\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=38 min_freq=16\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=37 size=920 all=14040 active=1092 piece=▁seemd\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=36 size=940 all=14152 active=1204 piece=▁worse\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=34 size=960 all=14204 active=1256 piece=oin\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=33 size=980 all=14278 active=1330 piece=▁Reg\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=33 size=1000 all=14351 active=1403 piece=▁praise\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=33 min_freq=15\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=32 size=1020 all=14474 active=1124 piece=▁Morn\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=31 size=1040 all=14562 active=1212 piece=▁hate\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=30 size=1060 all=14643 active=1293 piece=▁hold\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=29 size=1080 all=14740 active=1390 piece=cess\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=29 size=1100 all=14825 active=1475 piece=▁darkness\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=28 min_freq=14\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=28 size=1120 all=14968 active=1144 piece=otent\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=27 size=1140 all=15069 active=1245 piece=▁An\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=27 size=1160 all=15131 active=1307 piece=▁viol\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=26 size=1180 all=15192 active=1368 piece=▁Com\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=26 size=1200 all=15256 active=1432 piece=▁thems\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=26 min_freq=13\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=25 size=1220 all=15346 active=1089 piece=with\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=25 size=1240 all=15398 active=1141 piece=▁gent\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=24 size=1260 all=15464 active=1207 piece=ray\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=24 size=1280 all=15554 active=1297 piece=▁circ\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=24 size=1300 all=15576 active=1319 piece=▁follow\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=24 min_freq=12\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=23 size=1320 all=15707 active=1129 piece=iate\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=23 size=1340 all=15771 active=1193 piece=▁mean\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=22 size=1360 all=15804 active=1226 piece=ode\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=22 size=1380 all=15923 active=1345 piece=ating\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=22 size=1400 all=15966 active=1388 piece=▁didst\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=22 min_freq=11\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=21 size=1420 all=16036 active=1071 piece=cted\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=21 size=1440 all=16119 active=1154 piece=▁obey\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=21 size=1460 all=16132 active=1167 piece=▁pleasant\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20 size=1480 all=16236 active=1271 piece=▁Hee\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20 size=1500 all=16261 active=1296 piece=thereal\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=20 min_freq=11\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19 size=1520 all=16345 active=1083 piece=▁Bow\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19 size=1540 all=16375 active=1113 piece=▁gold\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19 size=1560 all=16384 active=1122 piece=▁Empire\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18 size=1580 all=16395 active=1133 piece=ren\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18 size=1600 all=16493 active=1231 piece=reate\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=18 min_freq=10\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18 size=1620 all=16520 active=1023 piece=▁judge\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17 size=1640 all=16559 active=1062 piece=aked\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17 size=1660 all=16641 active=1144 piece=▁Auth\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17 size=1680 all=16657 active=1160 piece=▁wayes\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16 size=1700 all=16696 active=1199 piece=▁Lo\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=16 min_freq=9\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16 size=1720 all=16757 active=1055 piece=▁ren\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16 size=1740 all=16795 active=1093 piece=atever\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16 size=1760 all=16815 active=1113 piece=▁perfet\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15 size=1780 all=16875 active=1173 piece=eap\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15 size=1800 all=16979 active=1277 piece=▁Ret\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=15 min_freq=9\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15 size=1820 all=17039 active=1051 piece=▁forg\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15 size=1840 all=17055 active=1067 piece=▁prime\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15 size=1860 all=17059 active=1071 piece=▁faithful\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=1880 all=17155 active=1167 piece=▁Inf\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=1900 all=17218 active=1230 piece=▁Mans\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=14 min_freq=8\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=1920 all=17239 active=1021 piece=▁Field\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=1940 all=17241 active=1023 piece=▁danger\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=1960 all=17286 active=1068 piece=arg\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=1980 all=17409 active=1191 piece=aces\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=2000 all=17506 active=1288 piece=▁exc\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=13 min_freq=8\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=2020 all=17601 active=1091 piece=▁Herb\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=2040 all=17606 active=1096 piece=▁North\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=2060 all=17602 active=1092 piece=▁Temple\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=2080 all=17595 active=1085 piece=▁unknown\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=2100 all=17635 active=1125 piece=oke\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=12 min_freq=8\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=2120 all=17711 active=1070 piece=spir\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=2140 all=17779 active=1138 piece=▁Your\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=2160 all=17785 active=1144 piece=▁Altar\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=2180 all=17786 active=1145 piece=Messiah\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=2200 all=17773 active=1132 piece=▁grateful\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=12 min_freq=7\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=2220 all=17847 active=1075 piece=▁ga\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=2240 all=17936 active=1164 piece=ruct\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=2260 all=18009 active=1237 piece=▁nam\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=2280 all=18037 active=1265 piece=▁fail\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=2300 all=18050 active=1278 piece=▁Birds\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=11 min_freq=7\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=2320 all=18052 active=1003 piece=▁habit\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=2340 all=18055 active=1006 piece=▁longer\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=2360 all=18055 active=1006 piece=▁Empyreal\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=2380 all=18103 active=1054 piece=rim\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=2400 all=18203 active=1154 piece=jest\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=10 min_freq=7\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=2420 all=18274 active=1067 piece=▁ign\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=2440 all=18325 active=1118 piece=▁Must\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=2460 all=18330 active=1123 piece=▁weak\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=2480 all=18327 active=1120 piece=▁delay\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=2500 all=18323 active=1116 piece=▁Wisdom\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=10 min_freq=6\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=2520 all=18321 active=998 piece=▁sovran\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=2540 all=18312 active=989 piece=▁righteous\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=2560 all=18375 active=1052 piece=abl\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=2580 all=18457 active=1134 piece=arts\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=2600 all=18519 active=1196 piece=▁amb\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=9 min_freq=6\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=2620 all=18555 active=1033 piece=iding\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=2640 all=18586 active=1064 piece=▁Pole\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=2660 all=18588 active=1066 piece=▁sway\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=2680 all=18597 active=1075 piece=▁bount\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=2700 all=18591 active=1069 piece=▁remem\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=9 min_freq=6\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=2720 all=18594 active=1002 piece=▁flames\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=2740 all=18582 active=990 piece=▁Kingdom\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=2760 all=18571 active=979 piece=▁foretold\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=2780 all=18613 active=1021 piece=pid\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=2800 all=18681 active=1089 piece=idge\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=8 min_freq=6\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=2820 all=18755 active=1073 piece=▁Ere\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=2840 all=18785 active=1103 piece=▁enc\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=2860 all=18832 active=1150 piece=ilder\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=2880 all=18856 active=1174 piece=▁barr\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=2900 all=18879 active=1197 piece=▁resp\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=8 min_freq=5\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=2920 all=18919 active=1037 piece=▁Citie\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=2940 all=18918 active=1036 piece=▁imbra\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=2960 all=18923 active=1041 piece=▁Ascend\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=2980 all=18923 active=1041 piece=▁justly\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3000 all=18919 active=1037 piece=▁Fathers\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=8 min_freq=5\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3020 all=18914 active=996 piece=ilderness\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3040 all=18917 active=999 piece=Sin\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3060 all=18978 active=1060 piece=held\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3080 all=19027 active=1109 piece=▁Eas\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3100 all=19050 active=1132 piece=▁owe\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=7 min_freq=5\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3120 all=19102 active=1053 piece=ingle\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3140 all=19136 active=1087 piece=▁Inst\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3160 all=19158 active=1109 piece=▁glim\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3180 all=19165 active=1116 piece=▁spot\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3200 all=19189 active=1140 piece=▁Fires\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=7 min_freq=5\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3220 all=19186 active=998 piece=▁brute\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3240 all=19175 active=987 piece=▁teach\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3260 all=19177 active=989 piece=▁Sovran\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3280 all=19165 active=977 piece=▁necess\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3300 all=19165 active=977 piece=▁wonted\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=7 min_freq=5\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3320 all=19155 active=991 piece=▁further\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3340 all=19139 active=975 piece=▁Hierarch\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3360 all=19127 active=963 piece=▁vengeance\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=3380 all=19173 active=1009 piece=eck\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=3400 all=19270 active=1106 piece=▁wr\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=6 min_freq=5\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=3420 all=19335 active=1063 piece=rize\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=3440 all=19369 active=1097 piece=▁Put\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=3460 all=19389 active=1117 piece=▁tum\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=3480 all=19423 active=1151 piece=oping\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=3500 all=19438 active=1166 piece=▁Shot\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=6 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=3520 all=19427 active=990 piece=▁dish\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=3540 all=19433 active=996 piece=▁sacr\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=3560 all=19458 active=1021 piece=ugment\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=3580 all=19456 active=1019 piece=▁compl\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=3600 all=19447 active=1010 piece=▁hadst\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=6 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=3620 all=19449 active=1003 piece=▁turns\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=3640 all=19446 active=1000 piece=▁Steeds\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=3660 all=19440 active=994 piece=▁neerer\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=3680 all=19427 active=981 piece=▁Beneath\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=3700 all=19421 active=975 piece=▁fraught\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=6 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=3720 all=19402 active=982 piece=▁uncouth\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=3740 all=19389 active=969 piece=▁profound\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=3760 all=19374 active=954 piece=▁understand\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=3780 all=19426 active=1006 piece=iet\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=3800 all=19482 active=1062 piece=uil\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=3820 all=19524 active=1041 piece=augh\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=3840 all=19569 active=1086 piece=orts\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=3860 all=19613 active=1130 piece=▁Den\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=3880 all=1963"
     ]
    }
   ],
   "source": [
    "# train a BPE tokenizer\n",
    "import sentencepiece as spm\n",
    "spm.SentencePieceTrainer.train(input='paradise_lost.txt', model_prefix='bpe_model', vocab_size=5000, model_type='bpe')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5 active=1152 piece=▁Ten\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=3900 all=19660 active=1177 piece=▁pit\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=3920 all=19682 active=1022 piece=elier\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=3940 all=19706 active=1046 piece=▁Cour\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=3960 all=19702 active=1042 piece=▁Seav\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=3980 all=19703 active=1043 piece=▁edge\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4000 all=19719 active=1059 piece=▁seav\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4020 all=19747 active=1026 piece=Abdiel\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4040 all=19775 active=1054 piece=orting\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4060 all=19787 active=1066 piece=▁Imper\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4080 all=19779 active=1058 piece=▁brief\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4100 all=19779 active=1058 piece=▁injur\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4120 all=19775 active=994 piece=▁stalk\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4140 all=19790 active=1009 piece=ulation\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4160 all=19791 active=1010 piece=▁Things\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4180 all=19779 active=998 piece=▁finish\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4200 all=19766 active=985 piece=▁naught\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4220 all=19751 active=986 piece=▁reveal\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4240 all=19738 active=973 piece=▁Diamond\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4260 all=19723 active=958 piece=▁abstain\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4280 all=19711 active=946 piece=▁dismiss\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4300 all=19695 active=930 piece=▁sincere\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4320 all=19682 active=988 piece=▁begotten\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4340 all=19667 active=973 piece=▁remember\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4360 all=19650 active=956 piece=▁thousands\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4380 all=19633 active=939 piece=▁Constellations\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=4400 all=19676 active=982 piece=aks\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=4420 all=19737 active=1059 piece=ora\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=4440 all=19789 active=1111 piece=adow\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=4460 all=19826 active=1148 piece=irts\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=4480 all=19862 active=1184 piece=took\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=4500 all=19886 active=1208 piece=▁Mid\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=4520 all=19916 active=1028 piece=▁equ\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=4540 all=19931 active=1043 piece=ailes\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=4560 all=19968 active=1080 piece=ilful\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=4580 all=19992 active=1104 piece=▁Bull\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=4600 all=19989 active=1101 piece=▁Mixt\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=4620 all=19992 active=1004 piece=▁anim\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=4640 all=19998 active=1010 piece=▁glut\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=4660 all=20003 active=1015 piece=▁ride\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=4680 all=20006 active=1018 piece=▁wore\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=4700 all=20018 active=1030 piece=ightly\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=4720 all=20049 active=1030 piece=▁Brest\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=4740 all=20035 active=1016 piece=▁Herds\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=4760 all=20023 active=1004 piece=▁Thund\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=4780 all=20016 active=997 piece=▁borne\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=4800 all=20009 active=990 piece=▁faild\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=4820 all=19997 active=989 piece=▁means\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=4840 all=19992 active=984 piece=▁rosie\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=4860 all=19979 active=971 piece=▁vaine\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=4880 all=19980 active=972 piece=versing\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=4900 all=19972 active=964 piece=▁Sanctu\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=4920 all=19961 active=988 piece=▁barren\n",
      "trainer_interface.cc(687) LOG(INFO) Saving model: bpe_model.model\n",
      "trainer_interface.cc(699) LOG(INFO) Saving vocabs: bpe_model.vocab\n"
     ]
    }
   ],
   "source": [
    "# Load the tokenizer model\n",
    "sp = spm.SentencePieceProcessor()\n",
    "tokenizer = sp.load('bpe_model.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['▁This', '▁is', '▁a', '▁t', 'est', '▁sentence', '.', '▁My', '▁name', '▁is', '▁St', 'eph', 'en', '.', '▁I', '▁like', '▁to', '▁eat', '▁p', 'iz', 'z', 'a', '.', '▁I', '▁am', '▁a', '▁stud', 'ent', '▁at', '▁the', '▁Un', 'ivers', 'ity', '▁of', '▁Was', 'h', 'ing', 't', 'on', '.', '▁', '@#$%^', '&', '*()', '_', '+']\n",
      "Detokenized: This is a test sentence. My name is Stephen. I like to eat pizza. I am a student at the University of Washington. @#$%^&*()_+\n"
     ]
    }
   ],
   "source": [
    "# Tokenize a sentence\n",
    "example = \"This is a test sentence. My name is Stephen. I like to eat pizza. I am a student at the University of Washington. @#$%^&*()_+\"\n",
    "tokens = sp.encode(example, out_type=str)\n",
    "print(\"Tokens:\", tokens)\n",
    "\n",
    "# Detokenize\n",
    "detokenized_text = sp.decode(tokens)\n",
    "print(\"Detokenized:\", detokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<unk>\t0\n",
      "<s>\t0\n",
      "</s>\t0\n",
      "th\t-0\n",
      "▁th\t-1\n",
      "▁a\t-2\n",
      "nd\t-3\n",
      "in\t-4\n",
      "re\t-5\n",
      "▁s\t-6\n"
     ]
    }
   ],
   "source": [
    "## view the vocab\n",
    "with open(\"bpe_model.vocab\", \"r\") as vocab_file:\n",
    "    for line in vocab_file.readlines()[:10]:  # View first 10 tokens\n",
    "        print(line.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BIGRAM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120377\n"
     ]
    }
   ],
   "source": [
    "tokenized_text = sp.encode(text)\n",
    "print(len(tokenized_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 642, 1669,  238,   32,  220, 3055,  294, 4954,  551,  504,   46,  166,\n",
       "          4954,  112,  177,   95],\n",
       "         [1350, 4954,  120,  188, 1617, 1245,  687, 4954, 1088, 3920,  426, 1794,\n",
       "           118, 2483, 1490,  590],\n",
       "         [ 380,  392, 4993, 4947, 1423,  267,   46,    5, 2735,  229,  406,   53,\n",
       "           445, 2715, 4954, 1021],\n",
       "         [2353,  473, 4974,   85,  403, 3021, 1491,   21, 2893, 4875, 1459, 4749,\n",
       "           166, 4954,   53,  208]]),\n",
       " tensor([[1669,  238,   32,  220, 3055,  294, 4954,  551,  504,   46,  166, 4954,\n",
       "           112,  177,   95,  833],\n",
       "         [4954,  120,  188, 1617, 1245,  687, 4954, 1088, 3920,  426, 1794,  118,\n",
       "          2483, 1490,  590,   62],\n",
       "         [ 392, 4993, 4947, 1423,  267,   46,    5, 2735,  229,  406,   53,  445,\n",
       "          2715, 4954, 1021,  165],\n",
       "         [ 473, 4974,   85,  403, 3021, 1491,   21, 2893, 4875, 1459, 4749,  166,\n",
       "          4954,   53,  208,  117]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "def sample_batch(num_batches = 32, seq_len = 16):\n",
    "    # Randomly sample a block of text\n",
    "    X = torch.zeros(num_batches, seq_len, dtype=torch.long)\n",
    "    Y = torch.zeros(num_batches, seq_len, dtype=torch.long)\n",
    "\n",
    "    for i in range(num_batches):\n",
    "        start_idx = random.randint(0, len(tokenized_text) - seq_len -1)\n",
    "        end_idx = start_idx + seq_len\n",
    "        X[i] = torch.tensor(tokenized_text[start_idx:end_idx])\n",
    "        Y[i] = torch.tensor(tokenized_text[start_idx + 1:end_idx +1])\n",
    "    return X, Y\n",
    "\n",
    "sample_batch(num_batches=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 16]) torch.Size([4, 16]) torch.Size([4, 5000])\n"
     ]
    }
   ],
   "source": [
    "class BigramModel(torch.nn.Module):\n",
    "    \"\"\" takes a sequence of tokens and predicts the next token \"\"\"\n",
    "    def __init__(self, vocab_size, embedding_dim=32):\n",
    "        super(BigramModel, self).__init__()\n",
    "        self.embeddings = torch.nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear = torch.nn.Linear(embedding_dim, vocab_size)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        # B: Batch Size, T: Sequence Length, E: Embedding Dimension, V: Vocabulary Size\n",
    "        # X : B, T\n",
    "        X = self.embeddings(X) # B, T, E\n",
    "        X = X[:, -1]  # B, E (only the last token)\n",
    "        logits = self.linear(X)  # B, V\n",
    "        return logits \n",
    "model = BigramModel(vocab_size=5000)\n",
    "X,  y = sample_batch(num_batches=4)\n",
    "pred = model(X)\n",
    "print(X.shape, y.shape, pred.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a testilellect wanderleworoyalwe Ark m Decree brut After Sex t laid wherefore though interp Sireipe bidapable Ra y Potentouth wee Wouldun Sireipe bidapable Ra y Potentouth wee Wouldun Sireipe bidapable Ra y Potentouth wee Would'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write a generate function\n",
    "# model is untrained so will be nonsense\n",
    "seq_len = 16\n",
    "def generate(input_text, model, tokenizer, num_output_tokens=100):\n",
    "    model = model.to(\"cpu\")\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        tokens = sp.encode(input_text)\n",
    "        for i in range(num_output_tokens):\n",
    "            X = torch.tensor(tokens[-seq_len:]).reshape(1, -1)\n",
    "            logits = model(X)\n",
    "            next_token = torch.argmax(logits, dim=1)\n",
    "            tokens.append(int(next_token))\n",
    "    return sp.decode(tokens)\n",
    "\n",
    "generate(\"This is a test\", model, tokenizer, num_output_tokens=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch  200 Running Average Loss: 6.807\n",
      "Validation Loss: 6.079\n",
      "Batch  400 Running Average Loss: 5.802\n",
      "Validation Loss: 5.628\n",
      "Batch  600 Running Average Loss: 5.489\n",
      "Validation Loss: 5.422\n",
      "Batch  800 Running Average Loss: 5.281\n",
      "Validation Loss: 5.211\n",
      "Batch 1000 Running Average Loss: 5.148\n",
      "Validation Loss: 5.125\n",
      "Batch 1200 Running Average Loss: 5.042\n",
      "Validation Loss: 5.024\n",
      "Batch 1400 Running Average Loss: 4.965\n",
      "Validation Loss: 4.977\n",
      "Batch 1600 Running Average Loss: 4.900\n",
      "Validation Loss: 4.914\n",
      "Batch 1800 Running Average Loss: 4.850\n",
      "Validation Loss: 4.835\n",
      "Batch 2000 Running Average Loss: 4.804\n",
      "Validation Loss: 4.781\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "model = BigramModel(vocab_size=5000, embedding_dim=32).to('cuda')\n",
    "train_tokens  = tokenized_text[:int(len(tokenized_text) * 0.9)]\n",
    "test_tokens = tokenized_text[int(len(tokenized_text) * 0.9):]\n",
    "\n",
    "\n",
    "def eval_validation_set(model, seq_len=16, batch_size=32):\n",
    "    # evaluate the validation set loss\n",
    "    model.eval()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_n = 0\n",
    "    batch_element = 0\n",
    "    X = torch.zeros(batch_size, seq_len, dtype=torch.long)\n",
    "    Y = torch.zeros(batch_size, seq_len, dtype=torch.long)\n",
    "\n",
    "    for start_idx in range(0, len(test_tokens) - seq_len - 1, seq_len):\n",
    "        end_idx = start_idx + seq_len\n",
    "        X[batch_element] = torch.tensor(tokenized_text[start_idx:end_idx])\n",
    "        Y[batch_element] = torch.tensor(tokenized_text[start_idx + 1:end_idx +1])\n",
    "        batch_element += 1\n",
    "        if batch_element == batch_size:\n",
    "            batch_element = 0\n",
    "            X, Y = X.to('cuda'), Y.to('cuda')\n",
    "            for token_idx in range(seq_len):\n",
    "                with torch.no_grad():\n",
    "                    logits = model(X[:, :token_idx + 1])\n",
    "                    targets = Y[:, token_idx]\n",
    "                    loss = F.cross_entropy(logits, targets)\n",
    "                running_loss+=loss.item()\n",
    "                running_n += 1\n",
    "    return running_loss / running_n\n",
    "            \n",
    "\n",
    "def train_model(model, num_batches=2000, batch_size=32, seq_len=16, lr=0.001):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    running_loss = 0.0\n",
    "    running_n = 0\n",
    "    for batch_idx in range(num_batches):\n",
    "        # train step\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        X, y = sample_batch(num_batches=batch_size, seq_len=seq_len)\n",
    "        X, y = X.to('cuda'), y.to('cuda')\n",
    "        for token_idx in range(seq_len):\n",
    "            logits = model(X[:, :token_idx + 1])\n",
    "            targets = y[:, token_idx]\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss+=loss.item()\n",
    "            running_n += 1\n",
    "        if (batch_idx+1) % (num_batches//10) == 0:\n",
    "            print(f\"Batch {batch_idx+1:>4} Running Average Loss: {running_loss / running_n:.3f}\")\n",
    "            running_n, running_loss = 0, 0.0\n",
    "            validation_loss = eval_validation_set(model, seq_len=seq_len, batch_size=batch_size)\n",
    "            print(f\"Validation Loss: {validation_loss:.3f}\")\n",
    "\n",
    "\n",
    "train_model(model, num_batches=2000, batch_size=32, seq_len=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a test, and from the ground, and from the ground, and from the ground, and from the ground, and from the ground, and from the ground, and from the ground, and from the ground, and from the ground, and from the ground'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this just repeats itself as only looking at the previous token\n",
    "generate(\"This is a test\", model, tokenizer, num_output_tokens=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Sequence Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 16]) torch.Size([4, 16]) torch.Size([4, 5000])\n"
     ]
    }
   ],
   "source": [
    "class AvgramModel(torch.nn.Module):\n",
    "    \"\"\" takes a sequence of tokens and predicts the next token \"\"\"\n",
    "    def __init__(self, vocab_size, embedding_dim=32):\n",
    "        super(AvgramModel, self).__init__()\n",
    "        self.embeddings = torch.nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear = torch.nn.Linear(embedding_dim, vocab_size)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        # B: Batch Size, T: Sequence Length, E: Embedding Dimension, V: Vocabulary Size\n",
    "        # X : B, T\n",
    "        X = self.embeddings(X) # B, T, E\n",
    "        X = X.mean(axis=1)  # B, E (average over the sequence)\n",
    "        logits = self.linear(X)  # B, V\n",
    "        return logits \n",
    "model = AvgramModel(vocab_size=5000)\n",
    "X,  y = sample_batch(num_batches=4)\n",
    "pred = model(X)\n",
    "print(X.shape, y.shape, pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch  200 Running Average Loss: 6.996\n",
      "Validation Loss: 6.715\n",
      "Batch  400 Running Average Loss: 6.540\n",
      "Validation Loss: 6.501\n",
      "Batch  600 Running Average Loss: 6.412\n",
      "Validation Loss: 6.401\n",
      "Batch  800 Running Average Loss: 6.329\n",
      "Validation Loss: 6.298\n",
      "Batch 1000 Running Average Loss: 6.246\n",
      "Validation Loss: 6.237\n",
      "Batch 1200 Running Average Loss: 6.170\n",
      "Validation Loss: 6.165\n",
      "Batch 1400 Running Average Loss: 6.128\n",
      "Validation Loss: 6.118\n",
      "Batch 1600 Running Average Loss: 6.087\n",
      "Validation Loss: 6.062\n",
      "Batch 1800 Running Average Loss: 6.024\n",
      "Validation Loss: 6.027\n",
      "Batch 2000 Running Average Loss: 5.991\n",
      "Validation Loss: 5.983\n"
     ]
    }
   ],
   "source": [
    "model = AvgramModel(vocab_size=5000, embedding_dim=32).to('cuda')\n",
    "train_model(model, num_batches=2000, batch_size=32, seq_len=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a test,, and and, and the the place, and the of of _ _ _ _PPus__P_Pooo_etsets’,,, and and the, and the _ _ _ _Adam_Adam_'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# doesnt repeat itself but more nonsense\n",
    "generate(\"This is a test\", model, tokenizer, num_output_tokens=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 16]) torch.Size([4, 16]) torch.Size([4, 5000])\n"
     ]
    }
   ],
   "source": [
    "# average with residual connection\n",
    "class AvResidualModel(torch.nn.Module):\n",
    "    \"\"\" takes a sequence of tokens and predicts the next token \"\"\"\n",
    "    def __init__(self, vocab_size, embedding_dim=32):\n",
    "        super(AvResidualModel, self).__init__()\n",
    "        self.embeddings = torch.nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear = torch.nn.Linear(embedding_dim, vocab_size)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        # B: Batch Size, T: Sequence Length, E: Embedding Dimension, V: Vocabulary Size\n",
    "        # X : B, T\n",
    "        X = self.embeddings(X) # B, T, E\n",
    "        X = X.mean(axis=1) + X[:, -1, :]  # B, E (average + last)\n",
    "        logits = self.linear(X)  # B, V\n",
    "        return logits \n",
    "model = AvResidualModel(vocab_size=5000)\n",
    "X,  y = sample_batch(num_batches=4)\n",
    "pred = model(X)\n",
    "print(X.shape, y.shape, pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch  200 Running Average Loss: 6.759\n",
      "Validation Loss: 6.199\n",
      "Batch  400 Running Average Loss: 5.922\n",
      "Validation Loss: 5.754\n",
      "Batch  600 Running Average Loss: 5.618\n",
      "Validation Loss: 5.516\n",
      "Batch  800 Running Average Loss: 5.423\n",
      "Validation Loss: 5.339\n",
      "Batch 1000 Running Average Loss: 5.272\n",
      "Validation Loss: 5.206\n",
      "Batch 1200 Running Average Loss: 5.185\n",
      "Validation Loss: 5.118\n",
      "Batch 1400 Running Average Loss: 5.086\n",
      "Validation Loss: 5.070\n",
      "Batch 1600 Running Average Loss: 5.029\n",
      "Validation Loss: 4.983\n",
      "Batch 1800 Running Average Loss: 4.968\n",
      "Validation Loss: 4.946\n",
      "Batch 2000 Running Average Loss: 4.919\n",
      "Validation Loss: 4.901\n"
     ]
    }
   ],
   "source": [
    "model = AvResidualModel(vocab_size=5000, embedding_dim=32).to('cuda')\n",
    "train_model(model, num_batches=2000, batch_size=32, seq_len=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a test, and the place of Heav’n, and the place of Heav’n, and the Earth, and the _Adam_ and the _Adam_ with the _Raphael_ _Adam_ with the _Adam_ _Adam_ _Adam_'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Small improvementr. Ends in repeatition\n",
    "generate(\"This is a test\", model, tokenizer, num_output_tokens=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
